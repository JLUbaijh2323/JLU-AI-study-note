---

Tags: #ROS2 #VLA #Python #Robotics #CodeDeepDive

Status: ğŸŸ¢ Implementation Ready

Target: èƒ½å¤Ÿæ‰‹å†™ä¸€ä¸ªé«˜å¯ç”¨ã€éé˜»å¡çš„ VLA æ¨ç†èŠ‚ç‚¹ã€‚

---

## ğŸ› ï¸ åœºæ™¯å®šä¹‰ï¼šOpenVLA è½åœ°å®æˆ˜

å‡è®¾æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå¼€æº VLA æ¨¡å‹ï¼ˆå¦‚ OpenVLA æˆ– RT-2 å˜ä½“ï¼‰ã€‚

- **è¾“å…¥**ï¼šRGB æ‘„åƒå¤´å›¾åƒ (`sensor_msgs/Image`) + æ–‡æœ¬æŒ‡ä»¤ (`std_msgs/String`)ã€‚
    
- **æ¨¡å‹åŠ¨ä½œ**ï¼šè¾“å‡º 7è‡ªç”±åº¦å…³èŠ‚æ§åˆ¶ä¿¡å· (6å…³èŠ‚ + 1å¤¹çˆª)ã€‚
    
- **è¾“å‡º**ï¼šå‘å¸ƒç»™æœºæ¢°è‡‚æ§åˆ¶å™¨çš„å…³èŠ‚æŒ‡ä»¤ (`trajectory_msgs/JointTrajectory`)ã€‚
    

---

## ğŸ’» æ ¸å¿ƒæ¨¡å—ä¸€ï¼šéé˜»å¡ VLA æ¨ç†èŠ‚ç‚¹ (The Non-Blocking Brain)

**ç³»ç»Ÿç—›ç‚¹**ï¼šVLA æ¨¡å‹æ¨ç†ä¸€æ¬¡å¯èƒ½éœ€è¦ 100ms~500msã€‚å¦‚æœç›´æ¥åœ¨ ROS2 çš„ `image_callback` é‡Œè·‘æ¨ç†ï¼Œä¼šå¡æ­»æ•´ä¸ªèŠ‚ç‚¹ï¼Œå¯¼è‡´ä¸¢å¸§æˆ–å¿ƒè·³è¶…æ—¶ã€‚

**å·¥ç¨‹è§£æ³•**ï¼š**ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼**ã€‚

1. **å›è°ƒçº¿ç¨‹ï¼ˆç”Ÿäº§è€…ï¼‰**ï¼šåªè´Ÿè´£æ”¶å›¾ï¼Œå­˜å…¥æœ€æ–°çš„ä¸€å¸§ï¼Œç«‹åˆ»è¿”å›ã€‚
    
2. **æ¨ç†çº¿ç¨‹ï¼ˆæ¶ˆè´¹è€…ï¼‰**ï¼šç‹¬ç«‹å¾ªç¯ï¼Œä»ç¼“å­˜å–å›¾ï¼Œè·‘æ¨¡å‹ï¼Œå‘æŒ‡ä»¤ã€‚
    

### ğŸ“œ ä»£ç å®ç° (Python)

Python

```
import rclpy
from rclpy.node import Node
from rclpy.callback_groups import ReentrantCallbackGroup
from rclpy.executors import MultiThreadedExecutor
from sensor_msgs.msg import Image
from std_msgs.msg import String
from trajectory_msgs.msg import JointTrajectory, JointTrajectoryPoint
from cv_bridge import CvBridge
import torch
import threading
import time
import numpy as np

class OpenVLANode(Node):
    def __init__(self):
        super().__init__('openvla_driver')
        
        # 1. æ ¸å¿ƒèµ„æºåˆå§‹åŒ–
        self.device = "cuda"
        self.bridge = CvBridge()
        self.latest_image = None
        self.latest_instruction = "do nothing"
        self.lock = threading.Lock() # çº¿ç¨‹é”ï¼Œä¿æŠ¤å›¾åƒæ•°æ®
        
        # 2. åŠ è½½æ¨¡å‹ (è€—æ—¶æ“ä½œï¼Œå»ºè®®æ”¾åœ¨è¿™é‡Œæˆ–å•ç‹¬çš„Loading State)
        self.get_logger().info("Loading VLA Model (Heavy)...")
        # self.model = OpenVLA.load_pretrained("openvla-7b").to(self.device)
        # ä¼ªä»£ç ï¼šé¢„çƒ­æ¨¡å‹ï¼Œé˜²æ­¢ç¬¬ä¸€æ¬¡æ¨ç†å¡é¡¿
        # self.model(dummy_input) 
        self.get_logger().info("Model Loaded!")

        # 3. è®¾ç½®å›è°ƒç»„ (Reentrant å…è®¸å¹¶å‘)
        self.cb_group = ReentrantCallbackGroup()

        # 4. è®¢é˜…è€… (Input)
        self.img_sub = self.create_subscription(
            Image, '/camera/rgb', self.image_callback, 1, callback_group=self.cb_group)
        self.txt_sub = self.create_subscription(
            String, '/vla/instruction', self.text_callback, 10, callback_group=self.cb_group)

        # 5. å‘å¸ƒè€… (Output) - æ§åˆ¶æœºæ¢°è‡‚
        self.cmd_pub = self.create_publisher(
            JointTrajectory, '/arm_controller/joint_trajectory', 10)

        # 6. å¯åŠ¨ç‹¬ç«‹æ¨ç†çº¿ç¨‹ (å…³é”®ï¼)
        self.inference_thread = threading.Thread(target=self.inference_loop)
        self.inference_thread.daemon = True # å®ˆæŠ¤çº¿ç¨‹ï¼ŒèŠ‚ç‚¹å…³äº†å®ƒä¹Ÿå…³
        self.inference_thread.start()

    def image_callback(self, msg):
        """ç”Ÿäº§è€…ï¼šåªè´Ÿè´£æ‹¿æ•°æ®ï¼Œä¸åšé‡è®¡ç®—"""
        try:
            # è½¬æ¢æ¯”è¾ƒå¿«ï¼Œå¯ä»¥åœ¨å›è°ƒé‡Œåšï¼Œä¹Ÿå¯ä»¥æ”¾åˆ°æ¨ç†çº¿ç¨‹
            cv_img = self.bridge.imgmsg_to_cv2(msg, "rgb8")
            with self.lock:
                self.latest_image = cv_img # æ°¸è¿œåªå­˜æœ€æ–°çš„ä¸€å¸§
        except Exception as e:
            self.get_logger().error(f"Img Error: {e}")

    def text_callback(self, msg):
        with self.lock:
            self.latest_instruction = msg.data

    def inference_loop(self):
        """æ¶ˆè´¹è€…ï¼šç‹¬ç«‹è·‘æ¨¡å‹ï¼Œä¸é˜»å¡ ROS é€šä¿¡"""
        rate = self.create_rate(5) # é™åˆ¶æ¨ç†é¢‘ç‡ï¼Œæ¯”å¦‚ 5Hz
        
        while rclpy.ok():
            # A. è·å–è¾“å…¥å¿«ç…§
            img_input = None
            txt_input = ""
            with self.lock:
                if self.latest_image is not None:
                    img_input = self.latest_image.copy()
                    txt_input = self.latest_instruction
            
            if img_input is None:
                time.sleep(0.1)
                continue

            # B. æ¨¡å‹æ¨ç† (æœ€è€—æ—¶éƒ¨åˆ†)
            try:
                # æ¨¡æ‹Ÿ VLA æ¨ç†ï¼šè¾“å…¥å›¾+æ–‡ï¼Œè¾“å‡º 7ä¸ªå…³èŠ‚åŠ¨ä½œå½’ä¸€åŒ–å€¼ [-1, 1]
                # action = self.model.predict(img_input, txt_input)
                action = np.random.uniform(-0.1, 0.1, 7) # æ¨¡æ‹Ÿè¾“å‡º
                
                # C. åŠ¨ä½œè§£ç ä¸å‘å¸ƒ
                self.publish_action(action)
                
            except Exception as e:
                self.get_logger().error(f"Inference Failed: {e}")

            rate.sleep() # ä¿æŒèŠ‚å¥

    def publish_action(self, raw_action):
        """å°†æ¨¡å‹è¾“å‡ºè½¬æ¢ä¸º ROS æœºæ¢°è‡‚æŒ‡ä»¤"""
        traj_msg = JointTrajectory()
        traj_msg.joint_names = ["joint1", "joint2", "joint3", "joint4", "joint5", "joint6", "gripper"]
        
        point = JointTrajectoryPoint()
        # å‡è®¾æ¨¡å‹è¾“å‡ºçš„æ˜¯ç›¸å¯¹å¢é‡ï¼Œæˆ‘ä»¬éœ€è¦åŠ ä¸Šå½“å‰ä½ç½® (å®é™…éœ€è¦è®¢é˜… /joint_states)
        # è¿™é‡Œç®€å•æ¼”ç¤ºç›´æ¥å‘é€
        point.positions = raw_action.tolist()
        point.time_from_start.sec = 0
        point.time_from_start.nanosec = 200 * 1000000 # æœŸæœ› 200ms åˆ°è¾¾

        traj_msg.points.append(point)
        self.cmd_pub.publish(traj_msg)

def main():
    rclpy.init()
    node = OpenVLANode()
    # ä½¿ç”¨å¤šçº¿ç¨‹æ‰§è¡Œå™¨ï¼Œç¡®ä¿å›¾åƒå›è°ƒå’ŒæŒ‡ä»¤å›è°ƒäº’ä¸å¹²æ‰°
    executor = MultiThreadedExecutor()
    executor.add_node(node)
    executor.spin()
    rclpy.shutdown()
```

### ğŸ’¡ ä»£ç ä¸­çš„é¢è¯•è€ƒç‚¹

1. **ä¸ºä»€ä¹ˆè¦ç”¨ `threading.Lock()`ï¼Ÿ**
    
    - å› ä¸º `image_callback` (ä¸»çº¿ç¨‹/æ‰§è¡Œå™¨çº¿ç¨‹) å’Œ `inference_loop` (ç‹¬ç«‹çº¿ç¨‹) éƒ½ä¼šè¯»å†™ `latest_image`ã€‚ä¸åŠ é”ä¼šå¯¼è‡´æ¨ç†çº¿ç¨‹è¯»åˆ°ä¸€å¼ å†™äº†ä¸€åŠçš„â€œèŠ±å±â€å›¾ç‰‡ã€‚
        
2. **ä¸ºä»€ä¹ˆè¦ç”¨ `latest_image.copy()`ï¼Ÿ**
    
    - ä¸ºäº†å°½å¿«é‡Šæ”¾é”ã€‚å¦‚æœæ¨ç†è¿‡ç¨‹ç›´æ¥å ç”¨ `latest_image`ï¼Œä¼šå¯¼è‡´å›è°ƒå‡½æ•°æƒ³è¦æ›´æ–°å›¾ç‰‡æ—¶è¢«é˜»å¡ã€‚**Copy ä¸€æ¬¡ï¼Œå„ç©å„çš„ã€‚**
        
3. **`daemon=True` æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ**
    
    - å®ˆæŠ¤çº¿ç¨‹ã€‚å¦‚æœä¸»ç¨‹åºï¼ˆROSèŠ‚ç‚¹ï¼‰è¢« Ctrl+C æ€æ­»äº†ï¼Œè¿™ä¸ªçº¿ç¨‹ä¼šè‡ªåŠ¨é™ªè‘¬ï¼Œä¸ä¼šå­¤é›¶é›¶åœ°ç•™åœ¨åå°å ç”¨æ˜¾å­˜ã€‚
        

---

## ğŸ§© æ ¸å¿ƒæ¨¡å—äºŒï¼šåŠ¨ä½œç©ºé—´è§£ç å™¨ (The Action Decoder)

VLA æ¨¡å‹è¾“å‡ºçš„é€šå¸¸æ˜¯ **Token** æˆ– **å½’ä¸€åŒ–æ•°å€¼**ï¼Œæœºå™¨äººè¦çš„æ˜¯ **å¼§åº¦/é€Ÿåº¦**ã€‚è¿™æ˜¯ç³»ç»Ÿå·¥ç¨‹å¸ˆå¿…é¡»å†™çš„â€œèƒ¶æ°´ä»£ç â€ã€‚

**åº”ç”¨æ•™å­¦ï¼šä» Logits åˆ° JointTrajectory**

Python

```
def decode_vla_action(self, model_output, current_joint_states):
    """
    å‡è®¾ OpenVLA è¾“å‡ºç¦»æ•£çš„ Action Token (0-255)ï¼Œå¯¹åº” [-1, 1] çš„åŠ¨ä½œç©ºé—´
    """
    # 1. åé‡åŒ– (De-quantization)
    # å°† 0-255 æ˜ å°„å› -1.0 åˆ° 1.0
    normalized_action = (model_output - 128) / 128.0 
    
    # 2. ç‰©ç†é‡æ˜ å°„ (Scaling)
    # æ¨¡å‹è¾“å‡º 1.0 å¯èƒ½ä»£è¡¨â€œæœ€å¤§é€Ÿåº¦â€æˆ–â€œç§»åŠ¨ 10cmâ€
    # è¿™é‡Œå‡è®¾æ˜¯ Delta Position (ä½ç½®å¢é‡)
    scale_factors = np.array([0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 1.0]) # å…³èŠ‚åŠ¨æ…¢ç‚¹ï¼Œå¤¹çˆªåŠ¨å¿«ç‚¹
    delta_q = normalized_action * scale_factors
    
    # 3. å®‰å…¨é™å¹… (Safety Clipping) - ç³»ç»Ÿå·¥ç¨‹å¸ˆçš„ä¿å‘½ç¬¦
    # é˜²æ­¢æ¨¡å‹å‘ç–¯è¾“å‡ºä¸€ä¸ªè®©æœºå™¨äººæ‰“è‡ªå·±çš„åŠ¨ä½œ
    target_q = current_joint_states + delta_q
    target_q = np.clip(target_q, self.JOINT_LIMITS_MIN, self.JOINT_LIMITS_MAX)
    
    return target_q
```

> [!TIP] VLA ç‰¹æœ‰å‘ç‚¹
> 
> å¾ˆå¤š VLA æ¨¡å‹ï¼ˆå¦‚ RT-2ï¼‰è¾“å‡ºçš„æ˜¯æœ«ç«¯æ‰§è¡Œå™¨ (End-Effector) çš„ä½å§¿ (x, y, z, r, p, y)ã€‚
> 
> æ­¤æ—¶ä½ çš„ ROS èŠ‚ç‚¹é‡Œéœ€è¦é›†æˆ é€†è¿åŠ¨å­¦ (IK, Inverse Kinematics) æ±‚è§£å™¨ï¼ˆå¦‚ MoveIt2 æˆ– KDLï¼‰ï¼ŒæŠŠ x,y,z ç®—æˆ joint_1, joint_2... æ‰èƒ½å‘ç»™æœºå™¨äººã€‚

---

## ğŸš€ æ ¸å¿ƒæ¨¡å—ä¸‰ï¼šLaunch å¯åŠ¨æ–‡ä»¶ (Deployment)

åœ¨å®é™…å·¥ä½œä¸­ï¼Œä½ ä¸ä¼šæ‰‹åŠ¨ `python run.py`ã€‚ä½ éœ€è¦å†™ `.launch.py` æ–‡ä»¶æ¥æ‹‰èµ·æ•´ä¸ª VLA ç³»ç»Ÿã€‚

**åº”ç”¨æ•™å­¦ï¼šå¸¦å‚æ•°çš„ Launch æ–‡ä»¶**

Python

```
from launch import LaunchDescription
from launch_ros.actions import Node
from launch.actions import DeclareLaunchArgument
from launch.substitutions import LaunchConfiguration

def generate_launch_description():
    # å…è®¸åœ¨å‘½ä»¤è¡Œä¿®æ”¹æ¨¡å‹è·¯å¾„ï¼šros2 launch my_pkg vla.launch.py model_type:=rt2-x
    model_arg = DeclareLaunchArgument(
        'model_type', default_value='openvla-7b'
    )

    vla_node = Node(
        package='vla_system',
        executable='vla_inference_node',
        name='vla_brain',
        output='screen',
        parameters=[
            {'model_path': LaunchConfiguration('model_type')},
            {'precision': 'fp16'},
            {'image_topic': '/head_camera/rgb'} # çµæ´»é‡æ˜ å°„ Topic
        ],
        # å…³é”®ï¼šç»™ VLA èŠ‚ç‚¹åˆ†é…è¶³å¤Ÿçš„æ˜¾å­˜å’Œä¼˜å…ˆçº§
        arguments=['--ros-args', '--log-level', 'info'] 
    )

    return LaunchDescription([
        model_arg,
        vla_node
    ])
```

---

## âš”ï¸ æ€»ç»“ï¼šVLA + ROS2 åº”ç”¨é¢˜æ£€æŸ¥è¡¨

å¦‚æœåœ¨é¢è¯•ä¸­è¢«è¦æ±‚**è®¾è®¡ä¸€ä¸ªæŠ“å–æ¯å­çš„ VLA ç³»ç»Ÿ**ï¼Œè¯·æŒ‰è¿™ä¸ªæ­¥éª¤å›ç­”ï¼š

1. **èŠ‚ç‚¹è®¾è®¡**ï¼šæˆ‘ä¼šè®¾è®¡ä¸€ä¸ª `VLAInferenceNode`ï¼Œé‡‡ç”¨**ç‹¬ç«‹æ¨ç†çº¿ç¨‹**æ¶æ„ï¼Œé¿å…é˜»å¡ ROS å¿ƒè·³ã€‚
    
2. **æ•°æ®è¾“å…¥**ï¼šä½¿ç”¨ `cv_bridge` å°† ROS å›¾åƒè½¬ä¸º Tensorï¼Œå¹¶åšå¥½**çº¿ç¨‹é”ä¿æŠ¤**ã€‚
    
3. **æ¨¡å‹æ¨ç†**ï¼šåŠ è½½ OpenVLA æ¨¡å‹ï¼Œä½¿ç”¨ TensorRT æˆ– ONNX Runtime åŠ é€Ÿï¼ˆå¦‚æœå¯èƒ½ï¼‰ï¼Œè¾“å‡º Action Tokenã€‚
    
4. **åŠ¨ä½œè§£ç **ï¼šç¼–å†™è§£ç å™¨ï¼Œå°† Token æ˜ å°„ä¸ºå…³èŠ‚å¢é‡ï¼Œå¹¶åŠ ä¸Š **IK è§£ç®—**ï¼ˆå¦‚æœè¾“å‡ºæ˜¯æœ«ç«¯ä½å§¿ï¼‰å’Œ **å…³èŠ‚é™ä½å®‰å…¨æ£€æŸ¥**ã€‚
    
5. **é€šä¿¡è¾“å‡º**ï¼šå‘å¸ƒ `JointTrajectory` ç»™åº•å±‚çš„ `ros2_control` èŠ‚ç‚¹æ‰§è¡Œã€‚
    

è¿™å¥—é€»è¾‘å±•ç¤ºäº†ä½ ä¸ä»…æ‡‚ AI æ¨¡å‹ï¼Œæ›´æ‡‚**æœºå™¨äººç³»ç»Ÿå·¥ç¨‹ (Robotics System Engineering)**ã€‚