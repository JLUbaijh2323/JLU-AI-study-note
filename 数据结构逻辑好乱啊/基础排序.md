
# 一、直接插入排序（Insertion Sort）

直观比喻：你洗扑克牌，手里一直维持一堆有序牌，新抽到的一张插到合适位置。

## 算法流程（伪代码 + 逐步流程）

伪代码：

```
for j = 2 .. n:
    key = A[j]
    i = j - 1
    while i >= 1 and A[i] > key:
        A[i+1] = A[i]    // 向后移动
        i = i - 1
    A[i+1] = key
```

逐步执行流程（把动作拆成原子步骤）：

1. 取第 j 个元素（key），把它暂存（手里的“新牌”）。
    
2. 从已排序区 `A[1..j-1]` 的右端（i = j-1）开始，比较 `A[i]` 与 `key`：
    
    - 若 `A[i] > key`，把 `A[i]` 向右移动一位（`A[i+1] = A[i]`），i--，继续比较。
        
    - 若 `A[i] <= key` 或 i < 1，则停止，把 `key` 放到 `A[i+1]`。
        
3. j++，重复。
    

### 手算示例：对 `[5,2,4,6,1,3]` 做插入（展示每次外循环后数组）

初始： `[5,2,4,6,1,3]`

- j=2, key=2: 比 5>2 → 移动 5 → 插入 2 → `[2,5,4,6,1,3]`
    
- j=3, key=4: 比 5>4 → 移动 5；比较 2<=4 → 插入 → `[2,4,5,6,1,3]`
    
- j=4, key=6: 5<=6 → 直接放 → `[2,4,5,6,1,3]`
    
- j=5, key=1: 移动 6,5,4,2 → 插入 1 → `[1,2,4,5,6,3]`
    
- j=6, key=3: 移动 6,5,4 → 插入 3 → `[1,2,3,4,5,6]`（结束）
    

## 不变量（正确性）

外循环开始时 `A[1..j-1]` 已经排序。每次插入使不变量在下一步仍成立，最终全部排序。

## 复杂度 / 空间 / 稳定

- 最好：`O(n)`（已排序）
    
- 平均/最坏：`O(n²)`（逆序）
    
- 额外空间：`O(1)`（原地）
    
- 稳定：**是**（相等元素相对顺序不变）
    

## 记忆技巧

- 画面：手里有序牌 → 插入新牌。
    
- 场景：当数组**几乎有序**时，插入排序非常快（常用作小数组排序或归并/快排的底层切换）。
    

# 二、冒泡排序（Bubble Sort）

直观比喻：相邻元素比较并交换，较大元素像气泡一样逐步“上浮”到右侧（或左侧）。

## 算法流程（基本版 + 改进版）

基本伪代码：

```
for i = n down to 2:
    for j = 1 .. i-1:
        if A[j] > A[j+1]:
            swap(A[j], A[j+1])
```

改进（早停 + bound）：

```
repeat:
    lastSwap = 0
    for j = 1 .. n-1:
        if A[j] > A[j+1]:
            swap(A[j], A[j+1])
            lastSwap = j
    n = lastSwap  // 下次只需到 lastSwap
until lastSwap == 0
```

逐步动作：

1. 每一趟，从左到右一次相邻比较并交换：较大的元素逐步右移。
    
2. 一趟结束，最大的元素到尾部（位置已确定）。
    
3. 缩小右端边界，重复。
    

### 手算示例：对 `[5,1,4,2]` 做冒泡（每趟结果）

初始 `[5,1,4,2]`

- 第一趟 comparisons:
    
    - 比 `5>1` → swap → `[1,5,4,2]`
        
    - 比 `5>4` → swap → `[1,4,5,2]`
        
    - 比 `5>2` → swap → `[1,4,2,5]` （5 到尾部）
        
- 第二趟:
    
    - `1<=4` → no swap → `[1,4,2,5]`
        
    - `4>2` → swap → `[1,2,4,5]`
        
- 第三趟:
    
    - `1<=2` → no swap; 无交换则提前结束 → `[1,2,4,5]`
        

## 反序对视角（理解交换次数）

每次交换减少 1 个反序对，最大反序对数量为 `n(n-1)/2`（逆序），这给出最坏交换次数的直观下界。

## 复杂度 / 空间 / 稳定

- 最好：`O(n)`（一次遍历无交换）
    
- 平均/最坏：`O(n²)`
    
- 空间：`O(1)`
    
- 稳定：**是**
    

## 记忆技巧

气泡上浮；如果看到“相邻交换”，就联想到冒泡或插入（区别在于插入保存并移动，冒泡不断交换）。

# 三、直接选择排序（Selection Sort）

直观比喻：每轮找到剩余元素中的最小（或最大），放到开头（或末尾），像一场“每轮淘汰赛”。

## 算法流程（伪代码）

```
for i = 1 .. n-1:
    minIndex = i
    for j = i+1 .. n:
        if A[j] < A[minIndex]:
            minIndex = j
    swap(A[i], A[minIndex])
```

逐步动作：

1. 在未排序区 `A[i..n]` 中遍历找最小元素下标 `minIndex`。
    
2. 将 `A[minIndex]` 与 `A[i]` 交换（把最小放到前面）。
    
3. i++，重复。
    

### 示例： `[64,25,12,22,11]`

- i=1 (找最小)：最小 11 (index 5) → swap → `[11,25,12,22,64]`
    
- i=2 (剩下找最小)：最小 12 (index 3) → swap → `[11,12,25,22,64]`
    
- i=3：最小 22 → swap → `[11,12,22,25,64]`
    
- i=4：剩 25,64 → swap（或保持） → `[11,12,22,25,64]`
    

## 特点

- 比较次数固定（不依赖初始顺序）：约 `n(n-1)/2` 次比较。
    
- 交换次数 ≤ n（每轮最多 1 次交换）。
    

## 复杂度 / 空间 / 稳定

- 时间：始终 `O(n²)`（最好/最坏相同）
    
- 空间：`O(1)`
    
- 稳定性：**通常不稳定**（交换可能改变相等元素的相对顺序）
    

## 记忆技巧

每轮“摘冠军”放到前面；若想让它稳定，需要避免直接 swap 或用额外结构记录并重建。

# 四、归并排序（Merge Sort）

直观比喻：把堆牌不断对半分，直到单张为序；然后两两合并成更大有序堆，直到合并成整堆。

## 算法流程（递归 + 合并）

伪代码：

```
MergeSort(A, p, r):
    if p >= r: return
    q = floor((p+r)/2)
    MergeSort(A, p, q)
    MergeSort(A, q+1, r)
    Merge(A, p, q, r)
```

合并（Merge）流程：

1. i = p, j = q+1, k = p (或向新临时数组写入)
    
2. 比较 `A[i]` 与 `A[j]`，把较小的写入输出位置，移动相应指针
    
3. 直到某侧耗尽，把另一侧剩余全部复制过去
    

### 进行示例：`A=[3,1,4,2]`

递归划分：

- 分成 `[3,1]` 和 `[4,2]`
    
- `[3,1]` → 分成 `[3]` `[1]` → 合并成 `[1,3]`
    
- `[4,2]` → `[2,4]`
    
- 合并 `[1,3]` 和 `[2,4]` → `[1,2,3,4]`
    

## 复杂度证明（递推树直观）

递推：`T(n) = 2T(n/2) + Θ(n)`  
把递归树画出来：每层合并总成本为 Θ(n)，高度 ≈ log₂ n → 总时间 Θ(n log n)。

## 空间 / 稳定 / 适用场景

- 额外空间：数组实现需 `O(n)`；链表实现可做到 `O(1)` 额外指针操作（但复杂度实现差异）。
    
- 稳定：**是**（合并阶段若实现时把 `<=` 的一边优先取，保持相等元素原相对顺序）。
    
- 适用：需要稳定或最坏时间保证时，外部排序/大数据排序，链表排序等。
    

## 记忆技巧

“分治＋每层成本为 n” → 直观地记住 `n log n`。画出一棵树写上每层 n，是最牢靠的记忆方式。

# 五、Shell 排序（插入的加速版）

直观比喻：先“跳着”分块排序（把数组分成步长为 gap 的若干子序列，用插入排序在每个子序列上排序），然后逐渐缩小 gap，最后 gap=1 相当于一次高效插入排序。

## 算法流程（常见实现）

```
gap = floor(n/2)
while gap > 0:
    for i = gap .. n-1:
        // 对以 i 为“插入点”的子序列用类似插入的方式
        temp = A[i]
        j = i
        while j >= gap and A[j-gap] > temp:
            A[j] = A[j-gap]
            j -= gap
        A[j] = temp
    gap = floor(gap/2)   // 或其它更好的序列
```

逐步动作：

1. 用初始 gap（如 n/2）把数组分为 gap 个子序列（按下标模 gap 分组）。
    
2. 对每个子序列做插入排序（相当于在该子序列内移动元素）。
    
3. 缩小 gap，重复直至 gap=1。
    

### 示例：`A=[8,9,1,7,2,3]`, gaps = [3,1]

gap=3：子序列索引组：{0,3},{1,4},{2,5}

- 对 {8,7} 做插入 → `7,8` 放回 → 位置变 `[7,9,1,8,2,3]`
    
- 对 {9,2} → `2,9` → `[7,2,1,8,9,3]`
    
- 对 {1,3} → `1,3` → `[7,2,1,8,9,3]`  
    gap=1：普通插入排序 → 最终 `[1,2,3,7,8,9]`
    

## 特点

- 时间复杂度依赖 gap 序列：没有统一简单界但通常优于 `O(n²)`，常见实测 `O(n^1.x)`。
    
- 空间：`O(1)`（原地）
    
- 稳定：**不稳定**
    

## 记忆技巧

把 Shell 想成“粗排→细排→精排”，类似先把桌面粗略整理再逐渐精细。

# 六、比较与如何选择（实用指南）

- 数据几乎有序：**插入排序**（最快、常数小）。
    
- 要稳定且在最坏情况下有 `O(n log n)`：**归并排序**（但需额外空间）。
    
- 要原地 `O(n log n)`：**堆排序**（你先跳过，为后面准备）。
    
- 工程常用：对中小规模数组，`quick/intro/merge` 混合实现（快排平均快，归并稳定，小段用插入）。
    
- 在面试/考场：知道每算法的**不变量**（插入的已排序子数组；归并的分治结构等）是加分点。
    

# 七、记忆与复习策略（快速掌握并记住）

1. **图像化**：把每个算法和一个清晰画面绑定（插入→手牌；冒泡→气泡；选择→比赛；归并→合并两堆；Shell→跳步插入）。
    
2. **不变量背诵**：每个算法至少记住一个核心不变量。例如：插入排序外循环开始时 `A[1..j-1]` 有序；归并每层合并成本为 Θ(n)。
    
3. **动手写**：对一个长度 6 的数组用每个算法亲手写出中间步骤（上面我已经给了示例）。
    
4. **口诀卡片**：写一个 A4，列出每种算法的复杂度、稳定性、空间、核心思想（我可以帮你生成 A4 打印版）。
    
5. **练习题**：在白板或纸上手动证明冒泡的交换次数等（反序对角度）。
    

# 八、练习题（建议立即做 3 道）

1. 用插入排序手算 `[9,8,3,7,5]`，写出每次移动后的数组与比较次数。
    
2. 用改进冒泡（记录 lastSwap）对 `[2,1,3,4,5]` 执行，写出每趟 lastSwap 值并说明为什么早停能节省时间。
    
3. 用归并排序画出 `n=8` 的递归树，写出每层合并成本并求总复杂度。
    

# 九、快速参考表（便于背诵）

- 插入：思想——手里有序牌插入；时间 `O(n²)`（最好 `O(n)`）；稳定；空间 `O(1)`。
    
- 冒泡：思想——相邻交换气泡上浮；时间 `O(n²)`（最好 `O(n)`）；稳定；空间 `O(1)`。
    
- 选择：思想——每轮选最小/最大；时间 `O(n²)` 固定；不稳定；空间 `O(1)`。
    
- 归并：思想——分治 + 合并；时间 `O(n log n)`；稳定；空间 `O(n)`（数组实现）。
    
- Shell：思想——分组插入（gap 逐步减小）；时间视 gap，不稳定；空间 `O(1)`。
    

---

我把重点都做成了**流程化、图像化、练习化**的说明，连带手算例子，方便你记忆与理解。  
接下来我可以（任选一项马上生成）：

- 把上面整理成 **一页 A4 的打印速查卡**（中文，便于背诵）；
    
- 生成 **5 道带详解的练习题**（手算步骤 + 解析）；
    
- 把所有伪代码转成 **可直接运行的 Python 实现**（含注释与测试用例），方便你实验。
    

你想马上要哪一个？（我不会再问要不要跳过快速/堆排序 —— 我知道你先让我们掠过它们；若你想我现在也补上快速/堆排序，我会直接展开。）

---

## 🧩 一、直接插入排序（Insertion Sort）

### ✅ C++实现

```cpp
#include <iostream>
#include <vector>
using namespace std;

void insertionSort(vector<int>& a) {
    int n = a.size();
    for (int j = 1; j < n; ++j) {  // 从第二个元素开始插入
        int key = a[j];            // 待插入元素
        int i = j - 1;
        // 将比 key 大的元素都向右移动
        while (i >= 0 && a[i] > key) {
            a[i + 1] = a[i];
            i--;
        }
        a[i + 1] = key;
    }
}
```

### 🔍 时间复杂度手推

设数组长度为 n：

- **外层循环**：`j = 1 .. n-1` → 约 n-1 次
    
- **内层 while 比较次数**：
    
    - 最好情况：数组已排序 ⇒ 每次只比较一次 ⇒ 总比较 ≈ n-1
        
    - 最坏情况：数组逆序 ⇒ 第 j 次要比较 j 次  
        ⇒ 比较总数：  
        [  
        1 + 2 + 3 + \dots + (n-1) = \frac{n(n-1)}{2} = O(n^2)  
        ]
        
    - 平均情况：假设一半元素要移动，平均比较 ≈ n²/4 ⇒ 仍是 O(n²)。
        
- **元素移动次数**：
    
    - 最好：0 次移动（除了赋值 key）
        
    - 最坏：每次移动 j 次 ⇒ 同样 O(n²)。
        

> ✅ **时间复杂度总结**  
> | 情况 | 比较次数 | 时间复杂度 |  
> |------|------------|-------------|  
> | 最好（已排好） | n-1 | O(n) |  
> | 平均 | n²/4 | O(n²) |  
> | 最坏（逆序） | n²/2 | O(n²) |

> ✅ **空间复杂度**：O(1)（原地）  
> ✅ **稳定性**：稳定  
> ✅ **适用场景**：小规模或基本有序数组

---

## 🫧 二、冒泡排序（Bubble Sort）

### ✅ C++实现

```cpp
void bubbleSort(vector<int>& a) {
    int n = a.size();
    bool swapped;
    for (int i = 0; i < n - 1; ++i) {
        swapped = false;
        for (int j = 0; j < n - i - 1; ++j) {
            if (a[j] > a[j + 1]) {
                swap(a[j], a[j + 1]);
                swapped = true;
            }
        }
        if (!swapped) break;  // 若一趟无交换则提前结束
    }
}
```

### 🔍 时间复杂度手推

- **外层循环**：i = 0..n-2 → n-1 次
    
- **内层循环**：比较次数每趟减少 1  
    [  
    (n-1) + (n-2) + \dots + 1 = \frac{n(n-1)}{2}  
    ]
    
- **最好情况**：数组已排好 ⇒ 第一次循环无交换 ⇒ 仅 O(n) 次比较
    
- **最坏情况**：逆序 ⇒ 每次都要交换 ⇒ 比较 + 交换总次数约 n²/2 ⇒ O(n²)
    

> ✅ **时间复杂度总结**  
> | 情况 | 比较次数 | 时间复杂度 |  
> |------|------------|-------------|  
> | 最好 | n-1 | O(n) |  
> | 平均 | n²/4 | O(n²) |  
> | 最坏 | n²/2 | O(n²) |

> ✅ **空间复杂度**：O(1)  
> ✅ **稳定性**：稳定  
> ✅ **适用场景**：教学 / 小数组；性能一般。

---

## 🏁 三、直接选择排序（Selection Sort）

### ✅ C++实现

```cpp
void selectionSort(vector<int>& a) {
    int n = a.size();
    for (int i = 0; i < n - 1; ++i) {
        int minIndex = i;
        for (int j = i + 1; j < n; ++j) {
            if (a[j] < a[minIndex])
                minIndex = j;
        }
        if (minIndex != i)
            swap(a[i], a[minIndex]);
    }
}
```

### 🔍 时间复杂度手推

- **比较次数固定，不依赖初始顺序**：  
    [  
    (n-1) + (n-2) + \dots + 1 = \frac{n(n-1)}{2} = O(n^2)  
    ]
    
- **交换次数**：每轮至多一次 → n-1 次
    

> ✅ **时间复杂度总结**  
> | 情况 | 比较次数 | 时间复杂度 |  
> |------|------------|-------------|  
> | 所有情况 | n²/2 | O(n²) |

> ✅ **空间复杂度**：O(1)  
> ✅ **稳定性**：不稳定（交换可能破坏相对顺序）  
> ✅ **特点**：比较固定、交换少，适合交换代价高的情况

---

## ⚙️ 四、归并排序（Merge Sort）

### ✅ C++实现

```cpp
void merge(vector<int>& a, int left, int mid, int right) {
    vector<int> temp(right - left + 1);
    int i = left, j = mid + 1, k = 0;

    while (i <= mid && j <= right) {
        if (a[i] <= a[j]) temp[k++] = a[i++];
        else temp[k++] = a[j++];
    }
    while (i <= mid) temp[k++] = a[i++];
    while (j <= right) temp[k++] = a[j++];

    for (int t = 0; t < k; ++t)
        a[left + t] = temp[t];
}

void mergeSort(vector<int>& a, int left, int right) {
    if (left >= right) return;
    int mid = (left + right) / 2;
    mergeSort(a, left, mid);
    mergeSort(a, mid + 1, right);
    merge(a, left, mid, right);
}
```

### 🔍 时间复杂度手推

设 T(n) 为长度 n 的排序时间：

1. 分解为两个长度 n/2 的子问题（2 次 T(n/2)）
    
2. 合并操作需遍历所有元素一次（Θ(n)）
    

递推式：  
[  
T(n) = 2T(n/2) + O(n)  
]

展开递推树：

|层|子问题个数|每层工作量|
|---|---|---|
|0（顶层）|1|n|
|1|2|2 × n/2 = n|
|2|4|4 × n/4 = n|
|...|...|...|
|log₂n|n|n|

→ 总层数约 log₂n，每层成本 n  
[  
T(n) = n × log₂n = O(n log n)  
]

> ✅ **时间复杂度总结**  
> | 情况 | 时间复杂度 |  
> |------|-------------|  
> | 最好 | O(n log n) |  
> | 平均 | O(n log n) |  
> | 最坏 | O(n log n) |

> ✅ **空间复杂度**：O(n)（需要临时数组）  
> ✅ **稳定性**：稳定  
> ✅ **适用场景**：大数据、外部排序、稳定要求高

---

## 🧮 五、Shell排序（Shell Sort）

### ✅ C++实现

```cpp
void shellSort(vector<int>& a) {
    int n = a.size();
    for (int gap = n / 2; gap > 0; gap /= 2) { // 动态减少gap
        for (int i = gap; i < n; ++i) {
            int temp = a[i];
            int j;
            for (j = i; j >= gap && a[j - gap] > temp; j -= gap) {
                a[j] = a[j - gap];
            }
            a[j] = temp;
        }
    }
}
```

### 🔍 时间复杂度手推

假设 gap 序列为 n/2, n/4, …, 1  
每次子序列内的插入排序代价取决于 gap 和分组数：

#### 直观估算：

- 最坏情况下：O(n²)（当 gap = 1 等价于插入排序）
    
- 最好情况下：O(n log n)（合理 gap 选择，如 Hibbard 序列）
    
- 实际平均常为 O(n^(1.25)) ～ O(n^(1.5))
    

没有严格统一表达式，因为复杂度依赖 gap 序列的数学性质。

> ✅ **空间复杂度**：O(1)  
> ✅ **稳定性**：不稳定  
> ✅ **适用场景**：中等规模排序，原地、常数小、比插入快

---

## 📊 六、总体对比表

|算法|最好时间|平均时间|最坏时间|空间|稳定|适用场景|
|---|---|---|---|---|---|---|
|插入|O(n)|O(n²)|O(n²)|O(1)|✅|小规模/基本有序|
|冒泡|O(n)|O(n²)|O(n²)|O(1)|✅|简单/教学|
|选择|O(n²)|O(n²)|O(n²)|O(1)|❌|交换代价高场合|
|归并|O(n log n)|O(n log n)|O(n log n)|O(n)|✅|稳定排序/外排|
|Shell|O(n log n)|≈O(n^1.3)|O(n²)|O(1)|❌|原地高效排序|

---

## 🧠 七、总结记忆思维导图（文字版）

```
排序算法分层理解：

插入类：
 ├─ 直接插入（稳定，O(n²)，适合小规模/近有序）
 └─ Shell（不稳定，O(n^1.x)，跳步插入加速）

交换类：
 └─ 冒泡（稳定，O(n²)，反序对减少）

选择类：
 └─ 直接选择（不稳定，比较固定，交换少）

分治类：
 └─ 归并（稳定，O(n log n)，空间O(n)，大数据/稳定性高）

```

---

# ⚙️ 详细解析 — 归并排序（Merge Sort）与 Shell 排序（Shell Sort）

下面把你贴出的 **归并** 与 **Shell** 的 C++ 实现做深入拆解：**算法流程、逐步执行示例、比较/移动计数上下界、不变量（正确性）证明、空间与性能细节、常见优化与实现陷阱、工程建议**。目标是让你看代码就能马上记住「为什么这样做」「性能从哪来」「怎么调优」。

---

# 1. 归并排序（Merge Sort）详细解析

### 代码回顾（你给的实现）

```cpp
void merge(vector<int>& a, int left, int mid, int right) {
    vector<int> temp(right - left + 1);
    int i = left, j = mid + 1, k = 0;

    while (i <= mid && j <= right) {
        if (a[i] <= a[j]) temp[k++] = a[i++];
        else temp[k++] = a[j++];
    }
    while (i <= mid) temp[k++] = a[i++];
    while (j <= right) temp[k++] = a[j++];

    for (int t = 0; t < k; ++t)
        a[left + t] = temp[t];
}
```

```cpp
void mergeSort(vector<int>& a, int left, int right) {
    if (left >= right) return;
    int mid = (left + right) / 2;
    mergeSort(a, left, mid);
    mergeSort(a, mid + 1, right);
    merge(a, left, mid, right);
}
```

---

## 1.1 算法流程（逐步）

- `mergeSort(a, L, R)`：
    
    1. 若 `L >= R`（区间长度 ≤ 1），返回（已排序）。
        
    2. 计算 `mid = (L+R)/2`，递归排序左右两部分 `L..mid` 和 `mid+1..R`。
        
    3. 调用 `merge(a, L, mid, R)` 把两段已排序子数组合并成一个有序数组放回 `a[L..R]`。
        
- `merge`（合并两个已排序区间 `L..mid` 与 `mid+1..R`）：
    
    1. 用 `i` 指向左段起点 `L`，`j` 指向右段起点 `mid+1`，`k` 为临时数组 `temp` 的写索引。
        
    2. 比较 `a[i]` 与 `a[j]`，把较小者写入 `temp[k++]`，并移动对应指针（`i++` 或 `j++`）。
        
    3. 一侧耗尽后，把另一侧剩余全部复制到 `temp`。
        
    4. 把 `temp` 的结果拷回 `a[L..R]`。
        

---

## 1.2 不变量与正确性（为什么 merge 保证排序）

- 递归不变量：进入 `mergeSort(a,L,R)` 时，`mergeSort(a,L,mid)` 与 `mergeSort(a,mid+1,R)` 返回后，两个子区间分别是**已排序的**。
    
- `merge` 保持：每次把左右头部中较小的元素放到输出，输出数组始终是已排序的前缀；当两侧都耗尽时输出就是两个已排序数组的合并结果。
    
- 由归纳法，`mergeSort` 对任意长度 `n` 正确。
    

---

## 1.3 复杂度精确手推（比较次数 / 复制次数上界/下界）

令 `n = R-L+1`，左段长度 `p = mid-L+1`，右段 `q = R-mid`，且 `p+q = n`。

### 合并（merge）阶段的成本

- **比较次数（merge 内）**：
    
    - 最坏：`p + q - 1 = n - 1` 次比较（当每次比较都选择一侧元素，但直到最后一次才耗尽一侧）。
        
    - 最好：`min(p, q)` 比较后一侧耗尽，然后剩余直接复制 —— 最少 `min(p, q)` 次比较。
        
    - 因此 `min(p,q) ≤ #comparisons ≤ n-1`。
        
- **写入（赋值）次数**：
    
    - `temp` 写操作恰好 `n` 次（把两段所有元素都写进 temp）。
        
    - 把 `temp` 拷回 `a` 又是 `n` 次写入（如果直接原地写回会有复杂性），总写入 ~ `2n`（可优化为 `n` 次用单缓冲在外部循环切换）。
        

### 整体 MergeSort 的渐近

- 递推关系： `T(n) = 2 T(n/2) + Θ(n)`
    
- 递推树直观：每层合并总工作量为 Θ(n)，树高为 Θ(log n) → 总体 `Θ(n log n)`。
    
- 对比较精确的界：比较次数总和在 `n log₂ n` 的常数倍区间内；一般可证明比较下界为 `n log n - O(n)`（基于比较树信息论下界），归并排序是接近最优的比较排序。
    

---

## 1.4 空间复杂度与内存行为

- 代码中每次 `merge` 都分配 `vector<int> temp(right-left+1)` → 若对每次合并都分配/释放，可能产生很多小的分配成本。
    
- **额外空间**：O(n)（总体上），但实现细节可能临时高峰略大。
    
- **工程建议**：使用一个单独的外部缓冲 `vector<int> buf(n)` 并在递归中传递引用（或做自底向上迭代时只需一个缓冲区并在两数组间交替使用），可以避免频繁分配：内存分配成本大幅降低，且效率更高。
    

---

## 1.5 稳定性

- `if (a[i] <= a[j]) temp[k++] = a[i++];` —— 使用 `<=` 而非 `<`，保证当相等时取左边元素优先，从而保持左边元素在合并后仍在前，**算法稳定**。
    

---

## 1.6 实战优化与常见实现陷阱

**优化建议**

1. **重用缓冲区**：在最外层创建 `buf(n)`，merge 时 `memcpy`/`std::copy` 到 `buf`，减少 `new`/`delete`。
    
2. **小段切换到插入排序**：当子数组长度小（如 ≤ 16）时，直接用插入排序能改善常数项，因为递归 + 合并的函数开销较大。
    
3. **自底向上（迭代）版本**：用宽度 `width = 1,2,4,...` 做迭代合并，避免递归开销且更利于利用缓存（cache-friendly）。
    
4. **避免额外拷贝**：若做双缓冲（在 `a` 和 `buf` 间交换），合并可以在两缓冲间直接写而不每次都拷回，最后可能要把结果保证在 `a` 中。
    

**常见陷阱**

- `mid = (left + right) / 2` 若 `left + right` 可能溢出（大索引），应写成 `left + (right-left)/2`。
    
- 每次都分配 `temp` 导致慢，注意 `reserve` 或外置缓冲。
    
- 在并行/多线程实现时，要注意缓存一致性与内存带宽瓶颈。
    

---

## 1.7 逐步示例（手推合并）

合并两个已排序数组 `[1,4,7]` 和 `[2,3,6,9]`：

- 比较 `1 vs 2` → 取 `1`
    
- 比较 `4 vs 2` → 取 `2`
    
- 比较 `4 vs 3` → 取 `3`
    
- 比较 `4 vs 6` → 取 `4`
    
- 比较 `7 vs 6` → 取 `6`
    
- 比较 `7 vs 9` → 取 `7`
    
- 右侧剩 `9` → 复制 `9`  
    比较次数 = 6 = `p+q-1`（最坏情况）
    

---

# 2. Shell 排序（Shell Sort）详细解析

### 代码回顾（你给的实现）

```cpp
void shellSort(vector<int>& a) {
    int n = a.size();
    for (int gap = n / 2; gap > 0; gap /= 2) {
        for (int i = gap; i < n; ++i) {
            int temp = a[i];
            int j;
            for (j = i; j >= gap && a[j - gap] > temp; j -= gap) {
                a[j] = a[j - gap];
            }
            a[j] = temp;
        }
    }
}
```

---

## 2.1 算法流程（直观）

- Shell 本质上是对不同 **gap**（步长）分组：对于当前 gap，把数组看成 gap 个子序列（索引 `r, r+gap, r+2gap, ...`），对每个子序列执行插入排序（按步长 gap）。
    
- 随着 gap 逐步缩小，数组逐渐“局部有序”，最终 gap = 1 时相当于对接近有序数组执行一次插入排序，因而整体效率好于直接插入排序。
    

---

## 2.2 不变量/正确性直觉

- 在任意迭代结束后（某个 gap 完成后），对于该 gap，数组在每个以 gap 为步长的子序列上是有序的。
    
- 当 gap 逐步缩小到 1 时，整个数组被保证有序（因为 gap=1 的插入排序在已经局部有序的数组上运行，移动次数少）。
    

---

## 2.3 gap 序列决定复杂度（关键点）

**最基础的 gap 选择**：`gap = n/2, n/4, ..., 1`（原 Shell 提议）

- 这种序列在最坏情况下仍是 `O(n^2)`。
    

**更好的序列（常见）**：

- **Hibbard**: `gap = 1, 3, 7, 15, ...`（`2^k - 1`）——最坏时间 `O(n^(3/2))`（已证明）。
    
- **Knuth**: `gap = (3^k - 1) / 2`（Knuth 提议）——实测常用且表现好。
    
- **Sedgewick** 和 **Tokuda** 等序列表现更好、理论更优（分别有 n^(4/3) 等界定）。
    
- **Ciura 序列（经验）**：`1,4,10,23,57,132,301,701,1750` —— 在实际工程中对中等 n 非常好（尽管理论边界未完全确定），许多实现采用 Ciura 的前几项然后按比例扩展。
    

**结论**：Shell 的理论复杂度依赖 gap 序列；实用上选择 Ciura / Sedgewick / Knuth 中的一种可得到很好的常数与平均行为。

---

## 2.4 复杂度手推（直观/限定）

- **最坏情形**：对某些 gap 序列（例如简单的 `n/2`）最坏仍可达 `O(n^2)`（当 gap=1 时退化为插入排序）。
    
- **理论上**：某些 gap 序列可把最坏复杂度降到 `O(n^(3/2))` 或 `O(n^(4/3))`（取决于数列构造）。
    
- **工程经验**：平均复杂度常介于 `O(n^(1.2)) ~ O(n^(1.5))`，对实用数组常明显快于简单插入/冒泡，且常数非常小。
    

---

## 2.5 比较/移动计数（定性）

- 每个 gap 的内循环是按 gap 步长的插入排序。若当前 gap 很大，子序列短但数量多；当 gap 逐渐变小，子序列长但“局部有序”，因此后期移动次数少。
    
- 没有简单的通用公式给出比较总数 / 移动总数（依赖 gap）。
    

---

## 2.6 稳定性

- **不稳定**：因为元素可能跨组交换而改变相等元素的相对顺序（比如当 gap > 1 时，相等的元素可能被移到不同组并重新排序）。
    

---

## 2.7 实现细节与工程建议

**实现注意**

- `for (int gap = n/2; gap > 0; gap /= 2)`：当用无符号索引（`size_t`）时，`j >= gap` 的循环和 `j -= gap` 要小心以免无意下变成非常大的正数——用 `int` 或显式检查条件。
    
- 内层 `for (j = i; j >= gap && a[j - gap] > temp; j -= gap)` 与插入排序一致，只是步长为 `gap`。
    
- 对稀疏数组（数值分布特殊）可能不均匀表现差异。
    

**优化建议**

1. **选择合适的 gap 序列**：使用 Ciura（工程上最常用）或 Knuth / Sedgewick 提升性能。
    
2. **对小规模数组使用插入排序**（gap 最后降到 1），这已内置于算法中。
    
3. **避免过多数据移动**：和插入排序一样用 `temp` 缓存当前元素，减少不必要的交换（这是你实现中已经采用的做法）。
    
4. **测试不同序列**：在你的输入分布（随机/逆序/近乎有序）上对比不同序列的表现。
    

---

## 2.8 逐步示例（演示 gap = 3,1）

数组：`[8,9,1,7,2,3]`，n=6，gap 序列假设 `[3,1]`：

- gap = 3：
    
    - 组0: indices 0,3 → `[8,7]` → 插入后 `[7,8]`
        
    - 组1: indices 1,4 → `[9,2]` → 插入后 `[2,9]`
        
    - 组2: indices 2,5 → `[1,3]` → 插入后 `[1,3]`
        
    - 结果数组中相对位置替换后变为 `[7,2,1,8,9,3]`（按照原索引把修改写回）
        
- gap = 1（普通插入）：
    
    - 在 `[7,2,1,8,9,3]` 上插入排序 → 结果 `[1,2,3,7,8,9]`
        

可以看到 gap=3 时把元素做了粗粒度的“预排序”，使得 gap=1 时插入变得轻松。

---

## 2.9 什么时候用 Shell？

- 要求**原地排序**且对常数因素敏感（例如不想申请额外 O(n) 内存），Shell 是不错的折中。
    
- 对中等规模数组，常比 `O(n^2)` 的插入/冒泡/选择快，且实现简单。
    
- 若需要最坏时间保证或稳定性，选择归并或堆排序（堆排序为原地 `O(n log n)`，但不稳定）。
    

---

# 3. 实用改进片段（代码级建议）

### 归并：重用缓冲区（示例）

```cpp
void merge_with_buf(vector<int>& a, vector<int>& buf, int left, int mid, int right) {
    int i = left, j = mid + 1, k = left;
    while (i <= mid && j <= right) {
        if (a[i] <= a[j]) buf[k++] = a[i++];
        else buf[k++] = a[j++];
    }
    while (i <= mid) buf[k++] = a[i++];
    while (j <= right) buf[k++] = a[j++];
    for (int t = left; t <= right; ++t) a[t] = buf[t];
}
void mergeSort_buf(vector<int>& a, vector<int>& buf, int left, int right) {
    if (left >= right) return;
    int mid = left + (right - left) / 2;
    mergeSort_buf(a, buf, left, mid);
    mergeSort_buf(a, buf, mid+1, right);
    merge_with_buf(a, buf, left, mid, right);
}
```

**优点**：只分配一次 `buf`（外部 `vector<int> buf(n);`），大幅减少动态分配开销。

### Shell：用 Ciura 序列（示例）

```cpp
void shellSort_ciura(vector<int>& a) {
    int n = a.size();
    int gaps[] = {701,301,132,57,23,10,4,1}; // Ciura 前几项（适合中等 n）
    for (int g : gaps) {
        if (g >= n) continue;
        for (int i = g; i < n; ++i) {
            int temp = a[i];
            int j;
            for (j = i; j >= g && a[j - g] > temp; j -= g) {
                a[j] = a[j - g];
            }
            a[j] = temp;
        }
    }
}
```

---

# 4. 常见面试/考试问法与简短回答模板（记忆卡）

- **“merge 的比较上界是多少？”** → 合并两个长为 p,q 的已排序数组最多比较 `p+q-1` 次；合并总写入 `n` 次（写回可能再 `n` 次）。
    
- **“mergeSort 的递推式？”** → `T(n) = 2T(n/2) + Θ(n)` → `Θ(n log n)`。
    
- **“Shell 最坏复杂度？”** → 取决 gap 序列，原始序列最坏 `O(n^2)`，某些序列（Hibbard、Sedgewick）可证明更好（e.g. O(n^(3/2))）。
    
- **“为什么 merge 是稳定的？”** → 合并时 `<=` 优先取左边，从而保留相等元素的相对先后顺序。
    
- **“Shell 是否稳定？”** → 不稳定（同值可能跨 gap 换位）。
    

---

# 5. 小结（记忆要点）

- **归并排序**：分治、每层花 `n`、层数 `log n` → `n log n`；稳定，但需要 `O(n)` 额外内存；工程实现时**重用缓冲区**和**对小段用插入排序**是常见优化。
    
- **Shell 排序**：插入排序的“跳步”版，**gap 序列**决定表现；不稳定、原地。实务中用 **Ciura / Knuth** 等序列获得非常好的常数表现。
    

---

如果你愿意：

- 我可以把上面两段的“示例运行（带计数比较与移动）”写成 **可运行的 C++ 测试程序**，让你输入一个数组输出每一步并统计比较/移动次数；或者
    
- 我可以把**归并的迭代（bottom-up）版本**与**带外部缓冲的递归版本**都给出完整代码并测试样例，便于你在本地运行对比。
    

你想要哪一个实战输出？我会直接贴完整代码并说明如何运行与预期输出。